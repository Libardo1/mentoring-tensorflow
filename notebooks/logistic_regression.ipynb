{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num examples\n",
      "train, valid, test\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f5396e64060f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"num examples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train, valid, test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# scikit-image: python imaging library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mnist' is not defined"
     ]
    }
   ],
   "source": [
    "# see how MNIST data look like\n",
    "print(\"num examples\")\n",
    "print(\"train, valid, test\")\n",
    "print(mnist.train.num_examples, mnist.validation.num_examples, mnist.test.num_examples)\n",
    "\n",
    "# scikit-image: python imaging library\n",
    "import skimage.io as io\n",
    "%matplotlib inline  \n",
    "# how next_batch work?\n",
    "# you don't need to know at this time...\n",
    "im = mnist.train.next_batch(1)[0].reshape(28, 28)\n",
    "io.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "MNIST image is (784,) shape, so if you want plot this you must reshape into (28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# tf placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 10]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# set model weights\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# construct model\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "\n",
    "# minimize error using cross entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "# gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost=1.181937457\n",
      "Epoch: 0002 cost=0.664753782\n",
      "Epoch: 0003 cost=0.552757355\n",
      "Epoch: 0004 cost=0.498688611\n",
      "Epoch: 0005 cost=0.465160990\n",
      "Epoch: 0006 cost=0.442533503\n",
      "Epoch: 0007 cost=0.425339254\n",
      "Epoch: 0008 cost=0.412169698\n",
      "Epoch: 0009 cost=0.401537917\n",
      "Epoch: 0010 cost=0.392290021\n",
      "Epoch: 0011 cost=0.384671018\n",
      "Epoch: 0012 cost=0.378475145\n",
      "Epoch: 0013 cost=0.372222680\n",
      "Epoch: 0014 cost=0.367216929\n",
      "Epoch: 0015 cost=0.362592109\n",
      "Epoch: 0016 cost=0.358764361\n",
      "Epoch: 0017 cost=0.354753922\n",
      "Epoch: 0018 cost=0.351453854\n",
      "Epoch: 0019 cost=0.347995837\n",
      "Epoch: 0020 cost=0.345692891\n",
      "Epoch: 0021 cost=0.342687203\n",
      "Epoch: 0022 cost=0.339984622\n",
      "Epoch: 0023 cost=0.338239727\n",
      "Epoch: 0024 cost=0.335848841\n",
      "Epoch: 0025 cost=0.333558215\n",
      "Optimization Finished!\n",
      "Accuracy: 0.8889999985694885\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,\n",
    "                                                      y: batch_ys})\n",
    "        # compute average loss\n",
    "        avg_cost += c / total_batch\n",
    "    # display logs per epoch step\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print(\"Epoch: {0:04d} cost={1:.9f}\" .format(epoch+1, avg_cost))\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "# test model\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "# calculate accuracy for 3000 examples\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy: {0}\"\n",
    "      .format(sess.run(accuracy, feed_dict={x: mnist.test.images[:3000], y: mnist.test.labels[:3000]})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARwAAAEZCAYAAABFOZpTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIU/WWZVRcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ecfcf9e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inference = tf.argmax(pred, 1)\n",
    "\n",
    "# plot one example\n",
    "ex_im = mnist.test.images[1000].reshape(1, -1)\n",
    "io.imshow(ex_im.reshape(28, 28))\n",
    "ex_pred = sess.run(inference, feed_dict={x:ex_im})\n",
    "print(ex_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
